import json 
import random 

original_stimuli_path = "js/original_stimuli.jsonl"

# Load the stimuli
stimuli_list = []
with open(original_stimuli_path, "r") as f:
    for line in f:
        stimuli_list.append(json.loads(line))

# Shuffle the stimuli
random.seed(3535)
random.shuffle(stimuli_list)

# Split into list of lists:
n_stimuli_per_list = 10
stimuli_lists = [stimuli_list[i:i + n_stimuli_per_list] for i in range(0, len(stimuli_list), n_stimuli_per_list)]

# Write to js script:
explainer = "// This file was generated by generate_stimuli_js.py\n// The data here was sourced from Pavlick & Kwiatkowski's (2019) original SNLI data -- we take the 20 SNLI datapoints with the lowest agreement, and then pick out 10 whose inter-annotator disagreements may be due to different world evaluations, as opposed to things like lexical ambiguity."
data_json_string = json.dumps(stimuli_lists)
with open("js/stimuli.js", "w") as f:
    f.write(f"{explainer}\n")
    f.write(f"var all_stimuli = {data_json_string};\n")

print("Done!")